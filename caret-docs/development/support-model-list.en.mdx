# Supported AI Models and Providers

Caret supports a wide variety of AI models and providers, giving you the freedom to choose the best tool for your needs.

## üöÄ Getting Started

1. **Prepare API Keys**: Get API keys from your preferred providers
2. **Configure Caret**: Click "Get Started" on the welcome page to set up APIs
3. **Select Models**: Choose your desired models in the settings page

> üìù **Updated**: 10/14/2025  
> üìß **Contact**: [GitHub Issues](https://github.com/aicoding-caret/caret/issues)

# üìä Model Support Overview

Total **20 providers** supporting **237 unique models** (317 total model definitions).

## üîç Models by Provider

| Provider | Model Count | Key Models |
|----------|-------------|------------|
| **Anthropic** | 11 | `claude-sonnet-4-5-20250929`, `claude-sonnet-4-5-20250929:1m`, `claude-sonnet-4-20250514` +8 more |
| **Claudecode** | 6 | `claude-sonnet-4-5-20250929`, `claude-sonnet-4-20250514`, `claude-opus-4-1-20250805` +3 more |
| **Bedrock** | 20 | `anthropic.claude-sonnet-4-5-20250929-v1:0`, `anthropic.claude-sonnet-4-5-20250929-v1:0:1m`, `anthropic.claude-sonnet-4-20250514-v1:0` +17 more |
| **Vertex** | 30 | `claude-sonnet-4-5@20250929`, `claude-sonnet-4@20250514`, `claude-opus-4-1@20250805` +27 more |
| **Gemini** | 15 | `gemini-2.5-pro`, `gemini-2.5-flash-lite-preview-06-17`, `gemini-2.5-flash` +12 more |
| **Openainative** | 14 | `gpt-5-2025-08-07`, `gpt-5-mini-2025-08-07`, `gpt-5-nano-2025-08-07` +11 more |
| **Deepseek** | 2 | `deepseek-chat`, `deepseek-reasoner` |
| **Huggingface** | 7 | `openai/gpt-oss-120b`, `openai/gpt-oss-20b`, `moonshotai/Kimi-K2-Instruct` +4 more |
| **Internationalqwen** | 30 | `qwen3-coder-plus`, `qwen3-coder-480b-a35b-instruct`, `qwen3-235b-a22b` +27 more |
| **Mainlandqwen** | 30 | `qwen3-235b-a22b`, `qwen3-32b`, `qwen3-30b-a3b` +27 more |
| **Doubao** | 4 | `doubao-1-5-pro-256k-250115`, `doubao-1-5-pro-32k-250115`, `deepseek-v3-250324` +1 more |
| **Mistral** | 13 | `mistral-large-2411`, `pixtral-large-2411`, `ministral-3b-2410` +10 more |
| **Asksage** | 31 | `gpt-4o`, `gpt-4o-gov`, `gpt-4.1` +28 more |
| **xAI** | 18 | `grok-4-fast-reasoning`, `grok-4`, `grok-3-beta` +15 more |
| **Sambanova** | 13 | `Llama-4-Maverick-17B-128E-Instruct`, `Llama-4-Scout-17B-16E-Instruct`, `Meta-Llama-3.3-70B-Instruct` +10 more |
| **Cerebras** | 7 | `gpt-oss-120b`, `qwen-3-coder-480b-free`, `qwen-3-coder-480b` +4 more |
| **Groq** | 11 | `openai/gpt-oss-120b`, `openai/gpt-oss-20b`, `compound-beta` +8 more |
| **Sapaicore** | 19 | `anthropic--claude-4-sonnet`, `anthropic--claude-4-opus`, `anthropic--claude-3.7-sonnet` +16 more |
| **Moonshot** | 5 | `kimi-k2-0905-preview`, `kimi-k2-0711-preview`, `kimi-k2-turbo-preview` +2 more |
| **Huaweicloudmaas** | 5 | `DeepSeek-V3`, `DeepSeek-R1`, `deepseek-r1-250528` +2 more |
| **Baseten** | 11 | `Qwen/Qwen3-235B-A22B-Instruct-2507`, `meta-llama/Llama-4-Maverick-17B-128E-Instruct`, `deepseek-ai/DeepSeek-R1` +8 more |
| **Internationalzai** | 3 | `glm-4.6`, `glm-4.5`, `glm-4.5-air` |
| **Mainlandzai** | 3 | `glm-4.6`, `glm-4.5`, `glm-4.5-air` |
| **Fireworks** | 6 | `accounts/fireworks/models/kimi-k2-instruct-0905`, `accounts/fireworks/models/kimi-k2-instruct`, `accounts/fireworks/models/qwen3-235b-a22b-instruct-2507` +3 more |
| **Qwencode** | 2 | `qwen3-coder-plus`, `qwen3-coder-flash` |
| **Caret** | 1 | `claude-sonnet-4-5` |

## üìã Complete Model Details

### Anthropic (11 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `claude-sonnet-4-5-20250929` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-sonnet-4-5-20250929:1m` | 8,192 | 1 | ‚úÖ | 3 | 15 |
| `claude-sonnet-4-20250514` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-sonnet-4-20250514:1m` | 8,192 | 1 | ‚úÖ | 3 | 15 |
| `claude-opus-4-1-20250805` | 8,192 | 200 | ‚úÖ | 15 | 75 |
| `claude-opus-4-20250514` | 8,192 | 200 | ‚úÖ | 15 | 75 |
| `claude-3-7-sonnet-20250219` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-3-5-sonnet-20241022` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-3-5-haiku-20241022` | 8,192 | 200 | ‚ùå | 0.8 | 4 |
| `claude-3-opus-20240229` | 4,096 | 200 | ‚úÖ | 15 | 75 |
| `claude-3-haiku-20240307` | 4,096 | 200 | ‚úÖ | 0.25 | 1.25 |

### Claudecode (6 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `claude-sonnet-4-5-20250929` | N/A | N/A | ‚ùå | N/A | N/A |
| `claude-sonnet-4-20250514` | N/A | N/A | ‚ùå | N/A | N/A |
| `claude-opus-4-1-20250805` | N/A | N/A | ‚ùå | N/A | N/A |
| `claude-opus-4-20250514` | N/A | N/A | ‚ùå | N/A | N/A |
| `claude-3-7-sonnet-20250219` | N/A | N/A | ‚ùå | N/A | N/A |
| `claude-3-5-haiku-20241022` | N/A | N/A | ‚ùå | N/A | N/A |

### Bedrock (20 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `anthropic.claude-sonnet-4-5-20250929-v1:0` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `anthropic.claude-sonnet-4-5-20250929-v1:0:1m` | 8,192 | 1 | ‚úÖ | 3 | 15 |
| `anthropic.claude-sonnet-4-20250514-v1:0` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `anthropic.claude-sonnet-4-20250514-v1:0:1m` | 8,192 | 1 | ‚úÖ | 3 | 15 |
| `anthropic.claude-opus-4-20250514-v1:0` | 8,192 | 200 | ‚úÖ | 15 | 75 |
| `anthropic.claude-opus-4-1-20250805-v1:0` | 8,192 | 200 | ‚úÖ | 15 | 75 |
| `amazon.nova-premier-v1:0` | 10 | 1 | ‚úÖ | 2.5 | 12.5 |
| `amazon.nova-pro-v1:0` | 5,000 | 300 | ‚úÖ | 0.8 | 3.2 |
| `amazon.nova-lite-v1:0` | 5,000 | 300 | ‚úÖ | 0.06 | 0.24 |
| `amazon.nova-micro-v1:0` | 5,000 | 128 | ‚ùå | 0.035 | 0.14 |
| `anthropic.claude-3-7-sonnet-20250219-v1:0` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `anthropic.claude-3-5-sonnet-20241022-v2:0` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `anthropic.claude-3-5-haiku-20241022-v1:0` | 8,192 | 200 | ‚úÖ | 0.8 | 4 |
| `anthropic.claude-3-5-sonnet-20240620-v1:0` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `anthropic.claude-3-opus-20240229-v1:0` | 4,096 | 200 | ‚úÖ | 15 | 75 |
| `anthropic.claude-3-sonnet-20240229-v1:0` | 4,096 | 200 | ‚úÖ | 3 | 15 |
| `anthropic.claude-3-haiku-20240307-v1:0` | 4,096 | 200 | ‚úÖ | 0.25 | 1.25 |
| `deepseek.r1-v1:0` | 8 | 64 | ‚ùå | 1.35 | 5.4 |
| `openai.gpt-oss-120b-1:0` | 8,192 | 128 | ‚ùå | 0.15 | 0.6 |
| `openai.gpt-oss-20b-1:0` | 8,192 | 128 | ‚ùå | 0.07 | 0.3 |

### Vertex (30 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `claude-sonnet-4-5@20250929` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-sonnet-4@20250514` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-opus-4-1@20250805` | 8,192 | 200 | ‚úÖ | 15 | 75 |
| `claude-opus-4@20250514` | 8,192 | 200 | ‚úÖ | 15 | 75 |
| `claude-3-7-sonnet@20250219` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-3-5-sonnet-v2@20241022` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-3-5-sonnet@20240620` | 8,192 | 200 | ‚úÖ | 3 | 15 |
| `claude-3-5-haiku@20241022` | 8,192 | 200 | ‚ùå | 1 | 5 |
| `claude-3-opus@20240229` | 4,096 | 200 | ‚úÖ | 15 | 75 |
| `claude-3-haiku@20240307` | 4,096 | 200 | ‚úÖ | 0.25 | 1.25 |
| `mistral-large-2411` | 128 | 128 | ‚ùå | 2 | 6 |
| `mistral-small-2503` | 128 | 128 | ‚úÖ | 0.1 | 0.3 |
| `codestral-2501` | 256 | 256 | ‚ùå | 0.3 | 0.9 |
| `llama-4-maverick-17b-128e-instruct-maas` | 128 | 1 | ‚úÖ | 0.35 | 1.15 |
| `llama-4-scout-17b-16e-instruct-maas` | 1 | 10 | ‚úÖ | 0.25 | 0.7 |
| `gemini-2.0-flash-001` | 8,192 | 1 | ‚úÖ | 0.15 | 0.6 |
| `gemini-2.0-flash-lite-001` | 8,192 | 1 | ‚úÖ | 0.075 | 0.3 |
| `gemini-2.0-flash-thinking-exp-1219` | 8,192 | 32 | ‚úÖ | 0 | 0 |
| `gemini-2.0-flash-exp` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-2.5-pro-exp-03-25` | 65,536 | 1 | ‚úÖ | 0 | 0 |
| `gemini-2.5-pro` | 65,536 | 1 | ‚úÖ | 2.5 | 15 |
| `gemini-2.5-flash` | 65,536 | 1 | ‚úÖ | 0.3 | 2.5 |
| `gemini-2.5-flash-lite-preview-06-17` | 64,000 | 1 | ‚úÖ | 0.1 | 0.4 |
| `gemini-2.0-flash-thinking-exp-01-21` | 65 | 1 | ‚úÖ | 0 | 0 |
| `gemini-exp-1206` | 8,192 | 2 | ‚úÖ | 0 | 0 |
| `gemini-1.5-flash-002` | 8,192 | 1 | ‚úÖ | 0.15 | 0.6 |
| `gemini-1.5-flash-exp-0827` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-1.5-flash-8b-exp-0827` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-1.5-pro-002` | 8,192 | 2 | ‚úÖ | 1.25 | 5 |
| `gemini-1.5-pro-exp-0827` | 8,192 | 2 | ‚úÖ | 0 | 0 |

### Gemini (15 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `gemini-2.5-pro` | 65,536 | 1 | ‚úÖ | 2.5 | 15 |
| `gemini-2.5-flash-lite-preview-06-17` | 64,000 | 1 | ‚úÖ | 0.1 | 0.4 |
| `gemini-2.5-flash` | 65,536 | 1 | ‚úÖ | 0.3 | 2.5 |
| `gemini-2.0-flash-001` | 8,192 | 1 | ‚úÖ | 0.1 | 0.4 |
| `gemini-2.0-flash-lite-preview-02-05` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-2.0-pro-exp-02-05` | 8,192 | 2 | ‚úÖ | 0 | 0 |
| `gemini-2.0-flash-thinking-exp-01-21` | 65 | 1 | ‚úÖ | 0 | 0 |
| `gemini-2.0-flash-thinking-exp-1219` | 8,192 | 32 | ‚úÖ | 0 | 0 |
| `gemini-2.0-flash-exp` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-1.5-flash-002` | 8,192 | 1 | ‚úÖ | 0.15 | 0.6 |
| `gemini-1.5-flash-exp-0827` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-1.5-flash-8b-exp-0827` | 8,192 | 1 | ‚úÖ | 0 | 0 |
| `gemini-1.5-pro-002` | 8,192 | 2 | ‚úÖ | 0 | 0 |
| `gemini-1.5-pro-exp-0827` | 8,192 | 2 | ‚úÖ | 0 | 0 |
| `gemini-exp-1206` | 8,192 | 2 | ‚úÖ | 0 | 0 |

### Openainative (14 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `gpt-5-2025-08-07` | 8 | 272,000 | ‚úÖ | 1.25 | 10 |
| `gpt-5-mini-2025-08-07` | 8 | 272,000 | ‚úÖ | 0.25 | 2 |
| `gpt-5-nano-2025-08-07` | 8 | 272,000 | ‚úÖ | 0.05 | 0.4 |
| `gpt-5-chat-latest` | 8 | 400,000 | ‚úÖ | 1.25 | 10 |
| `o4-mini` | 100 | 200 | ‚úÖ | 1.1 | 4.4 |
| `gpt-4.1` | 32 | 1 | ‚úÖ | 2 | 8 |
| `gpt-4.1-mini` | 32 | 1 | ‚úÖ | 0.4 | 1.6 |
| `gpt-4.1-nano` | 32 | 1 | ‚úÖ | 0.1 | 0.4 |
| `o3-mini` | 100 | 200 | ‚ùå | 1.1 | 4.4 |
| `o1-preview` | 32 | 128 | ‚úÖ | 15 | 60 |
| `o1-mini` | 65 | 128 | ‚úÖ | 1.1 | 4.4 |
| `gpt-4o` | 4 | 128 | ‚úÖ | 2.5 | 10 |
| `gpt-4o-mini` | 16 | 128 | ‚úÖ | 0.15 | 0.6 |
| `chatgpt-4o-latest` | 16 | 128 | ‚úÖ | 5 | 15 |

### Deepseek (2 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `deepseek-chat` | 8 | 128 | ‚ùå | 0 | 1.1 |
| `deepseek-reasoner` | 8 | 128 | ‚ùå | 0 | 2.19 |

### Huggingface (7 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `openai/gpt-oss-120b` | 32,766 | 131 | ‚ùå | 0 | 0 |
| `openai/gpt-oss-20b` | 32,766 | 131 | ‚ùå | 0 | 0 |
| `moonshotai/Kimi-K2-Instruct` | 131 | 131 | ‚ùå | 0 | 0 |
| `deepseek-ai/DeepSeek-V3-0324` | 8,192 | 64 | ‚ùå | 0 | 0 |
| `deepseek-ai/DeepSeek-R1` | 8,192 | 64 | ‚ùå | 0 | 0 |
| `deepseek-ai/DeepSeek-R1-0528` | 64 | 64 | ‚ùå | 0 | 0 |
| `meta-llama/Llama-3.1-8B-Instruct` | 8,192 | 128 | ‚ùå | 0 | 0 |

### Internationalqwen (30 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `qwen3-coder-plus` | 65 | 1 | ‚ùå | 1 | 5 |
| `qwen3-coder-480b-a35b-instruct` | 65 | 204 | ‚ùå | 1.5 | 7.5 |
| `qwen3-235b-a22b` | 16 | 131 | ‚ùå | 2 | 8 |
| `qwen3-32b` | 16 | 131 | ‚ùå | 2 | 8 |
| `qwen3-30b-a3b` | 16 | 131 | ‚ùå | 0.75 | 3 |
| `qwen3-14b` | 8 | 131 | ‚ùå | 1 | 4 |
| `qwen3-8b` | 8 | 131 | ‚ùå | 0.5 | 2 |
| `qwen3-4b` | 8 | 131 | ‚ùå | 0.3 | 1.2 |
| `qwen3-1.7b` | 8 | 32 | ‚ùå | 0.3 | 1.2 |
| `qwen3-0.6b` | 8 | 32 | ‚ùå | 0.3 | 1.2 |
| `qwen2.5-coder-32b-instruct` | 8 | 131 | ‚ùå | 0.002 | 0.006 |
| `qwen2.5-coder-14b-instruct` | 8 | 131 | ‚ùå | 0.002 | 0.006 |
| `qwen2.5-coder-7b-instruct` | 8 | 131 | ‚ùå | 0.001 | 0.002 |
| `qwen2.5-coder-3b-instruct` | 8 | 32 | ‚ùå | 0 | 0 |
| `qwen2.5-coder-1.5b-instruct` | 8 | 32 | ‚ùå | 0 | 0 |
| `qwen2.5-coder-0.5b-instruct` | 8 | 32 | ‚ùå | 0 | 0 |
| `qwen-coder-plus-latest` | 129 | 131 | ‚ùå | 3.5 | 7 |
| `qwen-plus-latest` | 16 | 131 | ‚ùå | 0.8 | 2 |
| `qwen-turbo-latest` | 16 | 1 | ‚ùå | 0.3 | 0.6 |
| `qwen-max-latest` | 30 | 32 | ‚ùå | 2.4 | 9.6 |
| `qwen-coder-plus` | 129 | 131 | ‚ùå | 3.5 | 7 |
| `qwen-plus` | 129 | 131 | ‚ùå | 0.8 | 2 |
| `qwen-turbo` | 1 | 1 | ‚ùå | 0.3 | 0.6 |
| `qwen-max` | 30 | 32 | ‚ùå | 2.4 | 9.6 |
| `deepseek-v3` | 8 | 64 | ‚ùå | 0 | 0.28 |
| `deepseek-r1` | 8 | 64 | ‚ùå | 0 | 2.19 |
| `qwen-vl-max` | 30 | 32 | ‚úÖ | 3 | 9 |
| `qwen-vl-max-latest` | 129 | 131 | ‚úÖ | 3 | 9 |
| `qwen-vl-plus` | 6 | 8 | ‚úÖ | 1.5 | 4.5 |
| `qwen-vl-plus-latest` | 129 | 131 | ‚úÖ | 1.5 | 4.5 |

### Mainlandqwen (30 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `qwen3-235b-a22b` | 16 | 131 | ‚ùå | 2 | 8 |
| `qwen3-32b` | 16 | 131 | ‚ùå | 2 | 8 |
| `qwen3-30b-a3b` | 16 | 131 | ‚ùå | 0.75 | 3 |
| `qwen3-14b` | 8 | 131 | ‚ùå | 1 | 4 |
| `qwen3-8b` | 8 | 131 | ‚ùå | 0.5 | 2 |
| `qwen3-4b` | 8 | 131 | ‚ùå | 0.3 | 1.2 |
| `qwen3-1.7b` | 8 | 32 | ‚ùå | 0.3 | 1.2 |
| `qwen3-0.6b` | 8 | 32 | ‚ùå | 0.3 | 1.2 |
| `qwen2.5-coder-32b-instruct` | 8 | 131 | ‚ùå | 0.002 | 0.006 |
| `qwen2.5-coder-14b-instruct` | 8 | 131 | ‚ùå | 0.002 | 0.006 |
| `qwen2.5-coder-7b-instruct` | 8 | 131 | ‚ùå | 0.001 | 0.002 |
| `qwen2.5-coder-3b-instruct` | 8 | 32 | ‚ùå | 0 | 0 |
| `qwen2.5-coder-1.5b-instruct` | 8 | 32 | ‚ùå | 0 | 0 |
| `qwen2.5-coder-0.5b-instruct` | 8 | 32 | ‚ùå | 0 | 0 |
| `qwen-coder-plus-latest` | 129 | 131 | ‚ùå | 3.5 | 7 |
| `qwen-plus-latest` | 16 | 131 | ‚ùå | 0.8 | 2 |
| `qwen-turbo-latest` | 16 | 1 | ‚ùå | 0.3 | 0.6 |
| `qwen-max-latest` | 30 | 32 | ‚ùå | 2.4 | 9.6 |
| `qwq-plus-latest` | 8 | 131 | ‚ùå | 0 | 0 |
| `qwq-plus` | 8 | 131 | ‚ùå | 0 | 0 |
| `qwen-coder-plus` | 129 | 131 | ‚ùå | 3.5 | 7 |
| `qwen-plus` | 129 | 131 | ‚ùå | 0.8 | 2 |
| `qwen-turbo` | 1 | 1 | ‚ùå | 0.3 | 0.6 |
| `qwen-max` | 30 | 32 | ‚ùå | 2.4 | 9.6 |
| `deepseek-v3` | 8 | 64 | ‚ùå | 0 | 0.28 |
| `deepseek-r1` | 8 | 64 | ‚ùå | 0 | 2.19 |
| `qwen-vl-max` | 30 | 32 | ‚úÖ | 3 | 9 |
| `qwen-vl-max-latest` | 129 | 131 | ‚úÖ | 3 | 9 |
| `qwen-vl-plus` | 6 | 8 | ‚úÖ | 1.5 | 4.5 |
| `qwen-vl-plus-latest` | 129 | 131 | ‚úÖ | 1.5 | 4.5 |

### Doubao (4 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `doubao-1-5-pro-256k-250115` | 12 | 256 | ‚ùå | 0.7 | 1.3 |
| `doubao-1-5-pro-32k-250115` | 12 | 32 | ‚ùå | 0.11 | 0.3 |
| `deepseek-v3-250324` | 12 | 128 | ‚ùå | 0.55 | 2.19 |
| `deepseek-r1-250120` | 32 | 64 | ‚ùå | 0.27 | 1.09 |

### Mistral (13 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `mistral-large-2411` | 128 | 128 | ‚ùå | 2 | 6 |
| `pixtral-large-2411` | 131 | 131 | ‚úÖ | 2 | 6 |
| `ministral-3b-2410` | 128 | 128 | ‚ùå | 0.04 | 0.04 |
| `ministral-8b-2410` | 128 | 128 | ‚ùå | 0.1 | 0.1 |
| `mistral-small-latest` | 128 | 128 | ‚úÖ | 0.1 | 0.3 |
| `mistral-medium-latest` | 128 | 128 | ‚úÖ | 0.4 | 2 |
| `mistral-small-2501` | 32 | 32 | ‚ùå | 0.1 | 0.3 |
| `pixtral-12b-2409` | 128 | 128 | ‚úÖ | 0.15 | 0.15 |
| `open-mistral-nemo-2407` | 128 | 128 | ‚ùå | 0.15 | 0.15 |
| `open-codestral-mamba` | 256 | 256 | ‚ùå | 0.15 | 0.15 |
| `codestral-2501` | 256 | 256 | ‚ùå | 0.3 | 0.9 |
| `devstral-small-2505` | 128 | 131 | ‚ùå | 0.1 | 0.3 |
| `devstral-medium-latest` | 128 | 131 | ‚ùå | 0.4 | 2 |

### Asksage (31 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `gpt-4o` | 4,096 | 128 | ‚ùå | 0 | 0 |
| `gpt-4o-gov` | 4,096 | 128 | ‚ùå | 0 | 0 |
| `gpt-4.1` | 32 | 1 | ‚ùå | 0 | 0 |
| `claude-35-sonnet` | 8,192 | 200 | ‚ùå | 0 | 0 |
| `aws-bedrock-claude-35-sonnet-gov` | 8,192 | 200 | ‚ùå | 0 | 0 |
| `claude-37-sonnet` | 8,192 | 200 | ‚ùå | 0 | 0 |
| `claude-4-sonnet` | 8,192 | 200 | ‚ùå | 0 | 0 |
| `claude-4-opus` | 8,192 | 200 | ‚ùå | 0 | 0 |
| `google-gemini-2.5-pro` | 65,536 | 1 | ‚ùå | 0 | 0 |
| `deepseek-ai/DeepSeek-V3` | 32 | 96 | ‚ùå | 0.5 | 1.5 |
| `deepseek-ai/DeepSeek-V3-0324-fast` | 128 | 128 | ‚ùå | 2 | 6 |
| `deepseek-ai/DeepSeek-R1` | 32 | 96 | ‚ùå | 0.8 | 2.4 |
| `deepseek-ai/DeepSeek-R1-fast` | 32 | 96 | ‚ùå | 2 | 6 |
| `deepseek-ai/DeepSeek-R1-0528` | 128 | 163 | ‚ùå | 0.8 | 2.4 |
| `meta-llama/Llama-3.3-70B-Instruct-fast` | 32 | 96 | ‚ùå | 0.25 | 0.75 |
| `Qwen/Qwen2.5-32B-Instruct-fast` | 8 | 32 | ‚ùå | 0.13 | 0.4 |
| `Qwen/Qwen2.5-Coder-32B-Instruct-fast` | 128 | 128 | ‚ùå | 0.1 | 0.3 |
| `Qwen/Qwen3-4B-fast` | 32 | 41 | ‚ùå | 0.08 | 0.24 |
| `Qwen/Qwen3-30B-A3B-fast` | 32 | 41 | ‚ùå | 0.3 | 0.9 |
| `Qwen/Qwen3-235B-A22B` | 32 | 41 | ‚ùå | 0.2 | 0.6 |
| `openai/gpt-oss-120b` | 32,766 | 131 | ‚ùå | 0.15 | 0.6 |
| `moonshotai/Kimi-K2-Instruct` | 16,384 | 131 | ‚ùå | 0.5 | 2.4 |
| `Qwen/Qwen3-Coder-480B-A35B-Instruct` | 163,800 | 262 | ‚ùå | 0.4 | 1.8 |
| `openai/gpt-oss-20b` | 32,766 | 131 | ‚ùå | 0.05 | 0.2 |
| `zai-org/GLM-4.5` | 98,304 | 128 | ‚ùå | 0.6 | 2.2 |
| `zai-org/GLM-4.5-Air` | 98,304 | 128 | ‚ùå | 0.2 | 1.2 |
| `deepseek-ai/DeepSeek-R1-0528-fast` | 128,000 | 164 | ‚ùå | 2 | 6 |
| `Qwen/Qwen3-235B-A22B-Instruct-2507` | 64,000 | 262 | ‚ùå | 0.2 | 0.6 |
| `Qwen/Qwen3-30B-A3B` | 32,000 | 41 | ‚ùå | 0.1 | 0.3 |
| `Qwen/Qwen3-32B` | 16,384 | 41 | ‚ùå | 0.1 | 0.3 |
| `Qwen/Qwen3-32B-fast` | 16,384 | 41 | ‚ùå | 0.2 | 0.6 |

### xAI (18 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `grok-4-fast-reasoning` | 30,000 | 2,000,000 | ‚úÖ | 0.2 | 0.5 |
| `grok-4` | 8,192 | 262,144 | ‚úÖ | 3 | 15 |
| `grok-3-beta` | 8,192 | 131,072 | ‚ùå | 3 | 15 |
| `grok-3-fast-beta` | 8,192 | 131,072 | ‚ùå | 5 | 25 |
| `grok-3-mini-beta` | 8,192 | 131,072 | ‚ùå | 0.3 | 0.5 |
| `grok-3-mini-fast-beta` | 8,192 | 131,072 | ‚ùå | 0.6 | 4 |
| `grok-3` | 8,192 | 131,072 | ‚ùå | 3 | 15 |
| `grok-3-fast` | 8,192 | 131,072 | ‚ùå | 5 | 25 |
| `grok-3-mini` | 8,192 | 131,072 | ‚ùå | 0.3 | 0.5 |
| `grok-3-mini-fast` | 8,192 | 131,072 | ‚ùå | 0.6 | 4 |
| `grok-2-latest` | 8,192 | 131,072 | ‚ùå | 2 | 10 |
| `grok-2` | 8,192 | 131,072 | ‚ùå | 2 | 10 |
| `grok-2-1212` | 8,192 | 131,072 | ‚ùå | 2 | 10 |
| `grok-2-vision-latest` | 8,192 | 32,768 | ‚úÖ | 2 | 10 |
| `grok-2-vision` | 8,192 | 32,768 | ‚úÖ | 2 | 10 |
| `grok-2-vision-1212` | 8,192 | 32,768 | ‚úÖ | 2 | 10 |
| `grok-vision-beta` | 8,192 | 8,192 | ‚úÖ | 5 | 15 |
| `grok-beta` | 8,192 | 131,072 | ‚ùå | 5 | 15 |

### Sambanova (13 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `Llama-4-Maverick-17B-128E-Instruct` | 4,096 | 8 | ‚úÖ | 0.63 | 1.8 |
| `Llama-4-Scout-17B-16E-Instruct` | 4,096 | 8 | ‚ùå | 0.4 | 0.7 |
| `Meta-Llama-3.3-70B-Instruct` | 4,096 | 128 | ‚ùå | 0.6 | 1.2 |
| `DeepSeek-R1-Distill-Llama-70B` | 4,096 | 128 | ‚ùå | 0.7 | 1.4 |
| `DeepSeek-R1` | 4,096 | 16 | ‚ùå | 5 | 7 |
| `Meta-Llama-3.1-405B-Instruct` | 4,096 | 16 | ‚ùå | 5 | 10 |
| `Meta-Llama-3.1-8B-Instruct` | 4,096 | 16 | ‚ùå | 0.1 | 0.2 |
| `Meta-Llama-3.2-1B-Instruct` | 4,096 | 16 | ‚ùå | 0.04 | 0.08 |
| `Meta-Llama-3.2-3B-Instruct` | 4,096 | 8 | ‚ùå | 0.08 | 0.16 |
| `Qwen3-32B` | 4,096 | 16 | ‚ùå | 0.4 | 0.8 |
| `QwQ-32B` | 4,096 | 16 | ‚ùå | 0.5 | 1 |
| `DeepSeek-V3-0324` | 4,096 | 8 | ‚ùå | 3 | 4.5 |
| `DeepSeek-V3.1` | 7,168 | 32 | ‚ùå | 3 | 4.5 |

### Cerebras (7 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `gpt-oss-120b` | 65,536 | 128,000 | ‚ùå | 0 | 0 |
| `qwen-3-coder-480b-free` | 40,000 | 64,000 | ‚ùå | 0 | 0 |
| `qwen-3-coder-480b` | 40,000 | 128,000 | ‚ùå | 0 | 0 |
| `qwen-3-235b-a22b-instruct-2507` | 64,000 | 64,000 | ‚ùå | 0 | 0 |
| `llama-3.3-70b` | 64,000 | 64,000 | ‚ùå | 0 | 0 |
| `qwen-3-32b` | 64,000 | 64,000 | ‚ùå | 0 | 0 |
| `qwen-3-235b-a22b-thinking-2507` | 32,000 | 65,000 | ‚ùå | 0 | 0 |

### Groq (11 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `openai/gpt-oss-120b` | 32,766 | 131 | ‚ùå | 0.15 | 0.75 |
| `openai/gpt-oss-20b` | 32,766 | 131 | ‚ùå | 0.1 | 0.5 |
| `compound-beta` | 8,192 | 128,000 | ‚ùå | 0 | 0 |
| `compound-beta-mini` | 8,192 | 128,000 | ‚ùå | 0 | 0 |
| `deepseek-r1-distill-llama-70b` | 131,072 | 131,072 | ‚ùå | 0.75 | 0.99 |
| `meta-llama/llama-4-maverick-17b-128e-instruct` | 8,192 | 131,072 | ‚úÖ | 0.2 | 0.6 |
| `meta-llama/llama-4-scout-17b-16e-instruct` | 8,192 | 131,072 | ‚úÖ | 0.11 | 0.34 |
| `llama-3.3-70b-versatile` | 32,768 | 131,072 | ‚ùå | 0.59 | 0.79 |
| `llama-3.1-8b-instant` | 131,072 | 131,072 | ‚ùå | 0.05 | 0.08 |
| `moonshotai/kimi-k2-instruct` | 16,384 | 131,072 | ‚ùå | 1 | 3 |
| `moonshotai/kimi-k2-instruct-0905` | 16,384 | 262,144 | ‚ùå | 0.6 | 2.5 |

### Sapaicore (19 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `anthropic--claude-4-sonnet` | 8,192 | 200 | ‚úÖ | N/A | N/A |
| `anthropic--claude-4-opus` | 8,192 | 200 | ‚úÖ | N/A | N/A |
| `anthropic--claude-3.7-sonnet` | 64 | 200 | ‚úÖ | N/A | N/A |
| `anthropic--claude-3.5-sonnet` | 8,192 | 200 | ‚úÖ | N/A | N/A |
| `anthropic--claude-3-sonnet` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `anthropic--claude-3-haiku` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `anthropic--claude-3-opus` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `gemini-2.5-pro` | 65,536 | 1 | ‚úÖ | N/A | N/A |
| `gemini-2.5-flash` | 65,536 | 1 | ‚úÖ | N/A | N/A |
| `gpt-4` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `gpt-4o` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `gpt-4o-mini` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `gpt-4.1` | 32 | 1 | ‚úÖ | N/A | N/A |
| `gpt-4.1-nano` | 32 | 1 | ‚úÖ | N/A | N/A |
| `gpt-5` | 128 | 272 | ‚úÖ | N/A | N/A |
| `gpt-5-nano` | 128 | 272 | ‚úÖ | N/A | N/A |
| `gpt-5-mini` | 128 | 272 | ‚úÖ | N/A | N/A |
| `o3-mini` | 4,096 | 200 | ‚úÖ | N/A | N/A |
| `o4-mini` | 100 | 200 | ‚úÖ | N/A | N/A |

### Moonshot (5 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `kimi-k2-0905-preview` | 16,384 | 262,144 | ‚ùå | 0.6 | 2.5 |
| `kimi-k2-0711-preview` | 32 | 131 | ‚ùå | 0.6 | 2.5 |
| `kimi-k2-turbo-preview` | 32 | 262 | ‚ùå | 2.4 | 10 |
| `moonshot-v1-128k-vision-preview` | 32 | 131 | ‚úÖ | 2 | 5 |
| `kimi-thinking-preview` | 32 | 131 | ‚ùå | 30 | 30 |

### Huaweicloudmaas (5 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `DeepSeek-V3` | 16 | 64 | ‚ùå | 0.27 | 1.1 |
| `DeepSeek-R1` | 16 | 64 | ‚ùå | 0.55 | 2.2 |
| `deepseek-r1-250528` | 16 | 64 | ‚ùå | 0.55 | 2.2 |
| `qwen3-235b-a22b` | 8 | 32 | ‚ùå | 0.27 | 1.1 |
| `qwen3-32b` | 8 | 32 | ‚ùå | 0.27 | 1.1 |

### Baseten (11 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `Qwen/Qwen3-235B-A22B-Instruct-2507` | 262,144 | 262,144 | ‚ùå | 0.22 | 0.8 |
| `meta-llama/Llama-4-Maverick-17B-128E-Instruct` | 131,072 | 1,000,000 | ‚ùå | 0.19 | 0.72 |
| `deepseek-ai/DeepSeek-R1` | 131,072 | 163,840 | ‚ùå | 2.55 | 5.95 |
| `deepseek-ai/DeepSeek-V3-0324` | 131,072 | 163,840 | ‚ùå | 0.77 | 0.77 |
| `meta-llama/Llama-4-Scout-17B-16E-Instruct` | 131,072 | 1,000,000 | ‚ùå | 0.13 | 0.5 |
| `deepseek-ai/DeepSeek-V3.1` | 131,072 | 163,840 | ‚ùå | 0.5 | 1.5 |
| `Qwen/Qwen3-Coder-480B-A35B-Instruct` | 262,144 | 262,144 | ‚ùå | 0.38 | 1.53 |
| `openai/gpt-oss-120b` | 128,072 | 128,072 | ‚ùå | 0.1 | 0.5 |
| `moonshotai/Kimi-K2-Instruct-0905` | 168,000 | 262,000 | ‚ùå | 0.6 | 2.5 |
| `moonshotai/Kimi-K2-Instruct` | 131,000 | 131,000 | ‚ùå | 0.6 | 2.5 |
| `deepseek-ai/DeepSeek-R1-0528` | 131,072 | 163,840 | ‚ùå | 2.55 | 5.95 |

### Internationalzai (3 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `glm-4.6` | 128 | 200 | ‚ùå | 0.6 | 2.2 |
| `glm-4.5` | 98 | 131 | ‚ùå | 0.6 | 2.2 |
| `glm-4.5-air` | 98,304 | 128 | ‚ùå | 0.2 | 1.2 |

### Mainlandzai (3 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `glm-4.6` | 128 | 200 | ‚ùå | 0.6 | 2.2 |
| `glm-4.5` | 98 | 131 | ‚ùå | 0.29 | 1.14 |
| `glm-4.5-air` | 98,304 | 128 | ‚ùå | 0.086 | 0.57 |

### Fireworks (6 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `accounts/fireworks/models/kimi-k2-instruct-0905` | 16,384 | 262,144 | ‚ùå | 0.6 | 2.5 |
| `accounts/fireworks/models/kimi-k2-instruct` | 16,384 | 128,000 | ‚ùå | 0.6 | 2.5 |
| `accounts/fireworks/models/qwen3-235b-a22b-instruct-2507` | 32,768 | 256,000 | ‚ùå | 0.22 | 0.88 |
| `accounts/fireworks/models/qwen3-coder-480b-a35b-instruct` | 32,768 | 256,000 | ‚ùå | 0.45 | 1.8 |
| `accounts/fireworks/models/deepseek-r1-0528` | 20,480 | 160,000 | ‚ùå | 3 | 8 |
| `accounts/fireworks/models/deepseek-v3` | 16,384 | 128,000 | ‚ùå | 0.9 | 0.9 |

### Qwencode (2 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `qwen3-coder-plus` | 65 | 1 | ‚ùå | 0 | 0 |
| `qwen3-coder-flash` | 65 | 1 | ‚ùå | 0 | 0 |

### Caret (1 models)

| Model Name | Max Tokens | Context Window | Image Support | Input Price ($/1M tokens) | Output Price ($/1M tokens) |
|------------|------------|----------------|---------------|-------------|--------------|
| `claude-sonnet-4-5` | 8,192 | 200,000 | ‚úÖ | 3 | 15 |


---

**Caret supports 237 unique AI models across 20 providers.**

*This document is automatically generated by `caret-scripts/generate-support-model-list.js`*
