---
title: "最初にお読みください"
---

## Clineでローカルモデルを実行する：知っておくべきこと 🤖

Clineは、コードの記述、分析、修正を支援するためにツール呼び出しを使用する強力なAIコーディングアシスタントです。ローカルでモデルを実行することでAPIコストを削減できる一方で、重要なトレードオフがあります：ローカルモデルは、これらの必須ツールの使用において大幅に信頼性が劣ります。

## ローカルモデルが異なる理由 🔬

モデルの「ローカル版」を実行する際、実際には元のモデルの大幅に簡略化されたコピーを実行しています。蒸留と呼ばれるこのプロセスは、プロのシェフの知識を基本的な料理本に圧縮しようとするようなもので、簡単なレシピは残しますが、複雑な技術と直感を失ってしまいます。

ローカルモデルは、より小さなモデルがより大きなモデルを模倣するように訓練されることで作成されますが、通常は元のモデルの容量の1〜26%しか保持できません。この大幅な削減は以下を意味します：

-   複雑なコンテキストを理解する能力の低下
-   多段階推論能力の削減
-   ツール使用能力の制限
-   単純化された意思決定プロセス

これは、コンピューターの代わりに電卓で開発環境を実行するようなもので、基本的なタスクは処理できるかもしれませんが、複雑な操作は信頼性が低くなるか不可能になります。

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/image%20(4).png"
		alt="Local model comparison diagram"
	/>
</Frame>

### 実際に起こること

Clineでローカルモデルを実行する場合：

#### パフォーマンスへの影響 📉

-   応答はクラウドサービスより5〜10倍遅い
-   システムリソース（CPU、GPU、RAM）が大量に使用される
-   他のタスクに対してコンピューターの応答性が低下する可能性がある

#### ツール信頼性の問題 🛠️

-   コード分析の精度が低下
-   ファイル操作が信頼できない場合がある
-   ブラウザー自動化機能が削減される
-   ターミナルコマンドがより頻繁に失敗する
-   複雑な多段階タスクがしばしば破綻する

### ハードウェア要件 💻

最低限必要なもの：

-   8GB以上のVRAMを持つ現代的なGPU（RTX 3070以上）
-   32GB以上のシステムRAM
-   高速SSDストレージ
-   良好な冷却ソリューション

このハードウェアを持っていても、より小さく、能力の劣るバージョンのモデルを実行することになります：

| モデルサイズ | 得られるもの                           |
| ---------- | --------------------------------------- |
| 7Bモデル    | 基本的なコーディング、制限されたツール使用     |
| 14Bモデル   | より良いコーディング、不安定なツール使用      |
| 32Bモデル   | 良いコーディング、一貫性のないツール使用      |
| 70Bモデル   | 最高のローカルパフォーマンス、ただし高価なハードウェアが必要 |

簡単に言えば、これらのモデルのクラウド（API）版は、モデルの完全版です。DeepSeek-R1の完全版は671Bです。これらの蒸留モデルは本質的にクラウドモデルの「薄められた」版です。

### 実用的な推奨事項 💡

#### このアプローチを検討してください

1. クラウドモデルの使用：
    - 複雑な開発タスク
    - ツールの信頼性が重要な場合
    - 多段階操作
    - 重要なコード変更
2. ローカルモデルの使用：
    - 単純なコード補完
    - 基本的なドキュメント作成
    - プライバシーが最優先の場合
    - 学習と実験

#### どうしてもローカルを使用する場合

-   より小さなモデルから始める
-   タスクをシンプルで集中したものに保つ
-   頻繁に作業を保存
-   複雑な操作にはクラウドモデルに切り替える準備をする
-   システムリソースを監視する

### 一般的な問題 🚨

-   **「ツール実行が失敗しました」:** ローカルモデルは複雑なツールチェーンで苦戦することがよくあります。プロンプトを簡素化してください。
-   **「ターゲットマシンによって積極的に拒否されたため、接続を確立できませんでした」:** 通常、これはOllamaまたはLM Studioサーバーが実行されていないか、Clineの設定と異なるポート/アドレスで実行されていることを意味します。APIプロバイダー設定のBase URLアドレスを再確認してください。
-   **「Clineに問題が発生しています...」:** モデルのコンテキスト長を最大サイズに増加してください。
-   **遅いまたは不完全な応答:** ローカルモデルはクラウドベースのモデルよりも遅いことがあり、特に非力なハードウェアではその傾向が顕著です。パフォーマンスが問題の場合は、より小さなモデルを使用してみてください。長い処理時間を予期してください。
-   **システム安定性:** GPU/CPU使用率と温度の上昇に注意
-   **コンテキストの制限:** ローカルモデルはクラウドモデルよりもコンテキストウィンドウが小さいことがよくあります。タスクを小さなピースに分割してください。

### 将来への展望 🔮

ローカルモデルの機能は向上していますが、特にClineのツールベースの機能において、クラウドサービスの完全な代替にはまだなっていません。ローカルのみのアプローチを採用する前に、あなたの特定のニーズとハードウェア機能を注意深く検討してください。

### サポートが必要ですか？ 🤝

-   [Discord](https://discord.gg/cline)コミュニティと[r/cline](https://www.reddit.com/r/CLine/)に参加
-   最新の互換性ガイドを確認
-   他の開発者と経験を共有

記憶しておいてください：迷ったときは、重要な開発作業ではコスト節約よりも信頼性を優先してください。
