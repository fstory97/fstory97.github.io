---
title: "Z AI (Zhipu AI)"
description: "Cline과 함께 Z AI의 GLM-4.5 모델을 구성하고 사용하는 방법을 알아보세요. 지역 최적화를 통해 고급 하이브리드 추론, 에이전트 기능 및 오픈 소스 우수성을 경험하세요."
---

Z AI(이전 Zhipu AI)는 하이브리드 추론 기능과 에이전트 AI 설계를 특징으로 하는 획기적인 GLM-4.5 시리즈를 제공합니다. 2025년 7월에 출시된 이 모델은 MIT 라이선스에 따라 오픈 소스 접근성을 유지하면서 통합 추론, 코딩 및 지능형 에이전트 애플리케이션에서 탁월합니다.

**웹사이트:** [https://z.ai/model-api](https://z.ai/model-api) (국제) | [https://open.bigmodel.cn/](https://open.bigmodel.cn/) (중국)

### API 키 얻기

#### 국제 사용자
1.  **가입/로그인:** [https://z.ai/model-api](https://z.ai/model-api)로 이동하세요. 계정을 만들거나 로그인하세요.
2.  **API 키로 이동:** 계정 대시보드에 액세스하여 API 키 섹션을 찾으세요.
3.  **키 생성:** 애플리케이션용 새 API 키를 생성하세요.
4.  **키 복사:** API 키를 즉시 복사하여 안전하게 보관하세요.

#### 중국 본토 사용자
1.  **가입/로그인:** [https://open.bigmodel.cn/](https://open.bigmodel.cn/)으로 이동하세요. 계정을 만들거나 로그인하세요.
2.  **API 키로 이동:** 계정 대시보드에 액세스하여 API 키 섹션을 찾으세요.
3.  **키 생성:** 애플리케이션용 새 API 키를 생성하세요.
4.  **키 복사:** API 키를 즉시 복사하여 안전하게 보관하세요.

### 지원되는 모델

Z AI는 선택한 지역에 따라 다른 모델 카탈로그를 제공합니다.

#### GLM-4.5 시리즈
-   **GLM-4.5** - 총 매개변수 355B, 활성 매개변수 32B의 플래그십 모델
-   **GLM-4.5-Air** - 총 매개변수 106B, 활성 매개변수 12B의 소형 모델

#### GLM-4.5 하이브리드 추론 모델
-   **GLM-4.5 (사고 모드)** - 단계별 분석을 통한 고급 추론
-   **GLM-4.5-Air (사고 모드)** - 주류 하드웨어에 효율적인 추론

모든 모델 기능:
-   광범위한 문서 처리를 위한 **128,000 토큰 컨텍스트 창**
-   최적의 성능을 위한 **전문가 혼합(MoE) 아키텍처**
-   추론, 코딩 및 도구 사용을 통합하는 **에이전트 기본 설계**
-   MIT 라이선스에 따른 **오픈 소스 가용성**

### Cline에서 구성

1.  **Cline 설정 열기:** Cline 패널에서 설정 아이콘(⚙️)을 클릭하세요.
2.  **공급자 선택:** "API 공급자" 드롭다운에서 "Z AI"를 선택하세요.
3.  **지역 선택:** 지역을 선택하세요.
    -   글로벌 액세스를 위한 "국제"
    -   중국 본토 액세스를 위한 "중국"
4.  **API 키 입력:** "Z AI API 키" 필드에 Z AI API 키를 붙여넣으세요.
5.  **모델 선택:** "모델" 드롭다운에서 원하는 모델을 선택하세요.

### Z AI의 하이브리드 인텔리전스

Z AI의 GLM-4.5 시리즈는 기존 언어 모델과 차별화되는 혁신적인 기능을 도입합니다.

#### 하이브리드 추론 아키텍처
GLM-4.5는 두 가지 고유한 모드로 작동합니다.
- **사고 모드:** 복잡한 추론 작업 및 도구 사용을 위해 설계되었으며, 더 깊은 분석 프로세스에 참여합니다.
- **비사고 모드:** 간단한 쿼리에 대한 즉각적인 응답을 제공하여 효율성을 최적화합니다.

이 이중 모드 아키텍처는 쿼리 복잡성에 따라 처리 강도를 조정하는 "에이전트 기본" 설계 철학을 나타냅니다.

#### 탁월한 성능
GLM-4.5는 에이전트 작업, 추론 및 코딩 과제를 포괄하는 12개 벤치마크에서 **63.2**의 종합 점수를 달성하여 모든 독점 및 오픈 소스 모델 중에서 **3위**를 차지했습니다. GLM-4.5-Air는 뛰어난 효율성을 제공하면서 **59.8**점의 경쟁력 있는 성능을 유지합니다.

#### 전문가 혼합 우수성
정교한 MoE 아키텍처는 계산 효율성을 유지하면서 성능을 최적화합니다.
- **GLM-4.5:** 총 매개변수 355B, 활성 매개변수 32B
- **GLM-4.5-Air:** 총 매개변수 106B, 활성 매개변수 12B

#### 확장된 컨텍스트 기능
128,000 토큰 컨텍스트 창은 광범위한 문서 및 코드베이스에 대한 포괄적인 이해를 가능하게 하며, 실제 테스트를 통해 거의 2,000줄의 코드베이스를 효과적으로 처리하면서 놀라운 성능을 유지함을 확인했습니다.

#### 오픈 소스 리더십
MIT 라이선스에 따라 출시된 GLM-4.5는 기본 모델, 하이브리드 추론 버전 및 최적화된 FP8 변형을 포함하여 독점 제한 없이 최첨단 기능에 대한 연구원 및 개발자 액세스를 제공합니다.

### 지역 최적화

#### API 엔드포인트
- **국제:** `https://api.z.ai/api/paas/v4` 사용
- **중국:** `https://open.bigmodel.cn/api/paas/v4` 사용

#### 모델 가용성
지역 설정은 API 엔드포인트와 사용 가능한 모델을 모두 결정하며, 선택한 지역과의 호환성을 보장하기 위해 자동 필터링이 적용됩니다.

### 특별 기능

#### 에이전트 기능
GLM-4.5의 통합 아키텍처는 통합 추론, 코딩 및 도구 활용 기능이 필요한 복잡한 지능형 에이전트 애플리케이션에 특히 적합합니다.

#### 포괄적인 벤치마킹
성능 평가는 다음을 포함합니다.
- **3가지 에이전트 작업 벤치마크**
- **7가지 추론 벤치마크**
- **2가지 코딩 벤치마크**

이 포괄적인 평가는 다양한 AI 애플리케이션 전반에 걸친 다재다능함을 보여줍니다.

#### 개발자 통합
모델은 여러 프레임워크를 통한 통합을 지원합니다.
- **transformers**
- **vLLM**
- **SGLang**

전용 모델 코드, 도구 파서 및 추론 파서 구현이 완료되었습니다.

### 성능 비교

#### vs Claude 4 Sonnet
GLM-4.5는 에이전트 코딩 및 추론 작업에서 경쟁력 있는 성능을 보여주지만, Claude Sonnet 4는 코딩 성공률 및 자율 다기능 애플리케이션 개발에서 이점을 유지합니다.

#### vs GPT-4.5
GLM-4.5는 추론 및 에이전트 벤치마크에서 경쟁력 있는 순위를 차지하며, GPT-4.5는 일반적으로 MMLU 및 AIME와 같은 전문 벤치마크에서 원시 작업 정확도에서 선두를 달립니다.

### 팁 및 참고 사항

-   **지역 선택:** 최적의 성능과 현지 규정 준수를 위해 적절한 지역을 선택하세요.
-   **모델 선택:** 최대 성능을 위해서는 GLM-4.5를, 효율성 및 주류 하드웨어 호환성을 위해서는 GLM-4.5-Air를 선택하세요.
-   **컨텍스트 이점:** 큰 128K 컨텍스트 창은 상당한 코드베이스 및 문서를 처리할 수 있도록 합니다.
-   **오픈 소스 이점:** MIT 라이선스는 상업적 사용 및 2차 개발을 모두 가능하게 합니다.
-   **에이전트 애플리케이션:** 추론, 코딩 및 도구 사용 통합이 필요한 애플리케이션에 특히 강력합니다.
-   **하이브리드 추론:** 복잡한 문제에는 사고 모드를, 간단한 쿼리에는 비사고 모드를 사용하세요.
-   **API 호환성:** OpenAI 호환 API는 스트리밍 응답 및 사용량 보고를 제공합니다.
-   **프레임워크 지원:** 다양한 배포 시나리오에 사용할 수 있는 여러 통합 옵션.
