---
title: "Groq"
description: "Cline과 함께 Groq의 초고속 추론을 구성하고 사용하는 방법을 알아보세요. Groq의 목적에 맞게 구축된 LPU 아키텍처에서 OpenAI, Meta, DeepSeek 등의 모델에 액세스하세요."
---

Groq는 훈련 하드웨어에서 개조된 것이 아니라 추론을 위해 특별히 제작된 맞춤형 LPU™(언어 처리 장치) 아키텍처를 통해 초고속 AI 추론을 제공합니다. Groq는 OpenAI, Meta, DeepSeek, Moonshot AI 등을 포함한 다양한 공급자의 오픈 소스 모델을 호스팅합니다.

**웹사이트:** [https://groq.com/](https://groq.com/)

### API 키 얻기

1.  **가입/로그인:** [Groq](https://groq.com/)로 이동하여 계정을 만들거나 로그인하세요.
2.  **콘솔로 이동:** 대시보드에 액세스하려면 [Groq 콘솔](https://console.groq.com/)로 이동하세요.
3.  **키 생성:** API 키 섹션으로 이동하여 새 API 키를 생성하세요. 키에 설명적인 이름(예: "Cline")을 지정하세요.
4.  **키 복사:** API 키를 즉시 복사하세요. 다시 볼 수 없습니다. 안전하게 보관하세요.

### 지원되는 모델

Cline은 다음 Groq 모델을 지원합니다.

-   `llama-3.3-70b-versatile` (Meta) - 131K 컨텍스트로 균형 잡힌 성능
-   `llama-3.1-8b-instant` (Meta) - 131K 컨텍스트로 빠른 추론
-   `openai/gpt-oss-120b` (OpenAI) - 131K 컨텍스트를 갖춘 주요 플래그십 모델
-   `openai/gpt-oss-20b` (OpenAI) - 131K 컨텍스트를 갖춘 주요 소형 모델
-   `moonshotai/kimi-k2-instruct` (Moonshot AI) - 프롬프트 캐싱을 지원하는 1조 매개변수 모델
-   `deepseek-r1-distill-llama-70b` (DeepSeek/Meta) - 추론에 최적화된 모델
-   `qwen/qwen3-32b` (Alibaba Cloud) - Q&A 작업에 최적화됨
-   `meta-llama/llama-4-maverick-17b-128e-instruct` (Meta) - 최신 Llama 4 변형
-   `meta-llama/llama-4-scout-17b-16e-instruct` (Meta) - 최신 Llama 4 변형

### Cline에서 구성

1.  **Cline 설정 열기:** Cline 패널에서 설정 아이콘(⚙️)을 클릭하세요.
2.  **공급자 선택:** "API 공급자" 드롭다운에서 "Groq"를 선택하세요.
3.  **API 키 입력:** "Groq API 키" 필드에 Groq API 키를 붙여넣으세요.
4.  **모델 선택:** "모델" 드롭다운에서 원하는 모델을 선택하세요.

### Groq의 속도 혁명

Groq의 LPU 아키텍처는 기존 GPU 기반 추론에 비해 몇 가지 주요 이점을 제공합니다.

#### LPU 아키텍처
훈련 워크로드에서 개조된 GPU와 달리 Groq의 LPU는 추론을 위해 특별히 제작되었습니다. 이는 기존 시스템에서 지연 시간을 유발하는 아키텍처 병목 현상을 제거합니다.

#### 타의 추종을 불허하는 속도
- 트래픽, 지역 및 워크로드 전반에 걸쳐 일관되게 유지되는 **밀리초 미만의 지연 시간**
- 미리 계산된 실행 그래프를 사용한 **정적 스케줄링**으로 런타임 조정 지연 제거
- 높은 처리량의 배치 처리보다는 낮은 지연 시간의 단일 응답에 최적화된 **텐서 병렬 처리**

#### 타협 없는 품질
- 정확도에 영향을 미치지 않는 영역에서만 정밀도를 줄이는 **TruePoint 수치**
- 손실 없는 계산을 보장하는 **100비트 중간 누적**
- BF16보다 2-4배 빠른 속도를 달성하면서 품질을 유지하는 **전략적 정밀도 제어**

#### 메모리 아키텍처
- 온칩에 수백 메가바이트를 갖춘 **SRAM을 기본 저장소로 사용** (캐시 아님)
- 기존 가속기를 괴롭히는 **DRAM/HBM 지연 시간 제거**
- 여러 칩에 걸쳐 레이어를 분할하여 **진정한 텐서 병렬 처리 가능**

Groq의 기술에 대한 자세한 내용은 [LPU 아키텍처 블로그 게시물](https://groq.com/blog/inside-the-lpu-deconstructing-groq-speed)에서 확인하세요.

### 특별 기능

#### 프롬프트 캐싱
Kimi K2 모델은 프롬프트 캐싱을 지원하여 반복되는 프롬프트에 대한 비용과 지연 시간을 크게 줄일 수 있습니다.

#### 비전 지원
선택한 모델은 이미지 입력 및 비전 기능을 지원합니다. 특정 기능은 Groq 콘솔의 모델 세부 정보를 확인하세요.

#### 추론 모델
DeepSeek 변형과 같은 일부 모델은 단계별 사고 프로세스를 통해 향상된 추론 기능을 제공합니다.

### 팁 및 참고 사항

-   **모델 선택:** 특정 사용 사례 및 성능 요구 사항에 따라 모델을 선택하세요.
-   **속도 이점:** Groq는 높은 처리량의 배치 처리보다는 단일 요청 지연 시간에 탁월합니다.
-   **OSS 모델 공급자:** Groq는 빠른 인프라에서 여러 공급자(OpenAI, Meta, DeepSeek 등)의 오픈 소스 모델을 호스팅합니다.
-   **컨텍스트 창:** 대부분의 모델은 상당한 코드와 컨텍스트를 포함할 수 있는 큰 컨텍스트 창(최대 131K 토큰)을 제공합니다.
-   **가격:** Groq는 속도 이점과 함께 경쟁력 있는 가격을 제공합니다. 현재 요금은 [Groq 가격](https://groq.com/pricing) 페이지를 확인하세요.
-   **속도 제한:** Groq는 관대한 속도 제한을 가지고 있지만, 사용량 계층에 따른 현재 제한은 문서를 확인하세요.
