---
title: "Fireworks AI"
description: "Cline과 함께 Fireworks AI의 초고속 추론 플랫폼을 구성하고 사용하는 방법을 알아보세요. 최적화된 모델과 경쟁력 있는 가격으로 최대 4배 빠른 추론 속도를 경험하세요."
---

Fireworks AI는 최적화된 추론 기능을 통해 탁월한 성능을 제공하는 데 중점을 둔 생성형 AI를 위한 선도적인 인프라 플랫폼입니다. 다른 플랫폼보다 최대 4배 빠른 추론 속도와 40가지 이상의 다양한 AI 모델 지원을 통해 Fireworks는 AI 모델을 대규모로 실행하는 데 따르는 운영 복잡성을 제거합니다.

**웹사이트:** [https://fireworks.ai/](https://fireworks.ai/)

### API 키 얻기

1.  **가입/로그인:** [Fireworks AI](https://fireworks.ai/)로 이동하여 계정을 만들거나 로그인하세요.
2.  **API 키로 이동:** 대시보드에서 API 키 섹션에 액세스하세요.
3.  **키 생성:** 새 API 키를 생성하세요. 설명적인 이름(예: "Cline")을 지정하세요.
4.  **키 복사:** API 키를 즉시 복사하세요. 안전하게 보관하세요.

### 지원되는 모델

Fireworks AI는 다양한 카테고리에 걸쳐 광범위한 모델을 지원합니다. 인기 있는 모델은 다음과 같습니다.

**텍스트 생성 모델:**
-   Llama 3.1 시리즈 (8B, 70B, 405B)
-   Mixtral 8x7B 및 8x22B
-   Qwen 2.5 시리즈
-   추론 기능을 갖춘 DeepSeek 모델
-   프로그래밍 작업을 위한 Code Llama 모델

**비전 모델:**
-   Llama 3.2 비전 모델
-   Qwen 2-VL 모델

**임베딩 모델:**
-   의미론적 검색을 위한 다양한 텍스트 임베딩 모델

이 플랫폼은 최대 성능을 위해 사용자 정의 커널 및 추론 최적화를 통해 모델을 선별, 최적화 및 배포합니다.

### Cline에서 구성

1.  **Cline 설정 열기:** Cline 패널에서 설정 아이콘(⚙️)을 클릭하세요.
2.  **공급자 선택:** "API 공급자" 드롭다운에서 "Fireworks"를 선택하세요.
3.  **API 키 입력:** "Fireworks API 키" 필드에 Fireworks API 키를 붙여넣으세요.
4.  **모델 ID 입력:** 사용할 모델을 지정하세요(예: "accounts/fireworks/models/llama-v3p1-70b-instruct").
5.  **토큰 구성:** 선택적으로 최대 완료 토큰 및 컨텍스트 창 크기를 설정하세요.

### Fireworks AI의 성능 중점

Fireworks AI의 경쟁 우위는 성능 최적화 및 개발자 경험에 중점을 둡니다.

#### 초고속 추론
- **다른 플랫폼보다 최대 4배 빠른 추론**
- 오픈 소스 추론 엔진에 비해 **250% 더 높은 처리량**
- **50% 더 빠른 속도**와 현저히 감소된 지연 시간
- HuggingFace 엔드포인트보다 **6배 낮은 비용**과 2.5배 빠른 생성 속도

#### 고급 최적화 기술
- **사용자 정의 커널** 및 추론 최적화로 GPU당 처리량 증가
- **Multi-LoRA 아키텍처**로 효율적인 리소스 공유 가능
- **수백 가지의 미세 조정된 모델 변형**이 공유 기본 모델 인프라에서 실행 가능
- **자산 경량 모델**은 값비싼 GPU 소유보다는 최적화 소프트웨어에 중점

#### 포괄적인 모델 지원
- 성능을 위해 선별 및 최적화된 **40개 이상의 다양한 AI 모델**
- **다중 GPU 유형** 지원: A100, H100, H200, B200, AMD MI300X
- 시작 시간에 대한 추가 요금 없이 **GPU 초당 요금 청구**
- 원활한 통합을 위한 **OpenAI API 호환성**

### 가격 구조

Fireworks AI는 경쟁력 있는 요금으로 사용량 기반 가격 모델을 사용합니다.

#### 텍스트 및 비전 모델 (2025)
| 매개변수 수 | 100만 입력 토큰당 가격 |
|---|---|
| 4B 매개변수 미만 | $0.10 |
| 4B - 16B 매개변수 | $0.20 |
| 16B 매개변수 초과 | $0.90 |
| MoE 0B - 56B 매개변수 | $0.50 |

#### 미세 조정 서비스
| 기본 모델 크기 | 100만 학습 토큰당 가격 |
|---|---|
| 최대 16B 매개변수 | $0.50 |
| 16.1B - 80B 매개변수 | $3.00 |
| DeepSeek R1 / V3 | $10.00 |

#### 전용 배포
| GPU 유형 | 시간당 가격 |
|---|---|
| A100 80GB | $2.90 |
| H100 80GB | $5.80 |
| H200 141GB | $6.99 |
| B200 180GB | $11.99 |
| AMD MI300X | $4.99 |

### 특별 기능

#### 미세 조정 기능
Fireworks는 MongoDB Atlas와 같은 데이터베이스의 JSON 형식 데이터를 지원하는 CLI 인터페이스를 통해 액세스할 수 있는 정교한 미세 조정 서비스를 제공합니다. 미세 조정된 모델은 추론을 위해 기본 모델과 동일한 비용이 듭니다.

#### 개발자 경험
- 직접적인 모델 상호 작용을 위한 **브라우저 플레이그라운드**
- OpenAI 호환성을 갖춘 **REST API**
- 바로 사용할 수 있는 레시피가 포함된 **포괄적인 요리책**
- 서버리스에서 전용 GPU에 이르는 **다중 배포 옵션**

#### 엔터프라이즈 기능
- 규제 산업을 위한 **HIPAA 및 SOC 2 Type II 준수**
- 개발자를 위한 **셀프 서비스 온보딩**
- 대규모 배포를 위한 **엔터프라이즈 판매**
- **후불 결제 옵션** 및 비즈니스 티어

#### 추론 모델 지원
`<think>` 태그 처리 및 추론 콘텐츠 추출을 통해 추론 모델에 대한 고급 지원을 제공하여 복잡한 다단계 추론을 실시간 애플리케이션에 실용적으로 만듭니다.

### 성능 이점

Fireworks AI의 최적화는 측정 가능한 개선 사항을 제공합니다.
- 오픈 소스 엔진 대비 **250% 더 높은 처리량**
- 지연 시간 감소로 **50% 더 빠른 속도**
- 다른 대안 대비 **6배 비용 절감**
- 요청당 **2.5배 생성 속도** 향상

### 팁 및 참고 사항

-   **모델 선택:** 특정 사용 사례에 따라 모델을 선택하세요. 속도를 위해서는 더 작은 모델을, 복잡한 추론을 위해서는 더 큰 모델을 사용하세요.
-   **성능 중점:** Fireworks는 고급 최적화를 통해 AI 추론을 빠르고 비용 효율적으로 만드는 데 탁월합니다.
-   **미세 조정:** 독점 데이터를 사용하여 모델 정확도를 향상시키기 위해 미세 조정 기능을 활용하세요.
-   **규정 준수:** HIPAA 및 SOC 2 Type II 준수를 통해 규제 산업에서 사용할 수 있습니다.
-   **가격 모델:** 사용량 기반 가격 책정은 기존의 좌석 기반 모델이 아닌 성공에 따라 확장됩니다.
-   **개발자 리소스:** 광범위한 문서 및 요리책 레시피는 구현 속도를 높입니다.
-   **GPU 옵션:** 성능 요구 사항에 따라 전용 배포를 위해 여러 GPU 유형을 사용할 수 있습니다.
